{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"%pip install -q pytorch-crf seqeval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:46:09.861915Z","iopub.execute_input":"2024-12-24T22:46:09.862166Z","iopub.status.idle":"2024-12-24T22:46:17.215357Z","shell.execute_reply.started":"2024-12-24T22:46:09.862141Z","shell.execute_reply":"2024-12-24T22:46:17.214276Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/bborisggg/chinese_word_segmentation.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:46:17.217304Z","iopub.execute_input":"2024-12-24T22:46:17.217633Z","iopub.status.idle":"2024-12-24T22:46:22.646259Z","shell.execute_reply.started":"2024-12-24T22:46:17.217596Z","shell.execute_reply":"2024-12-24T22:46:22.645188Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'chinese_word_segmentation'...\nremote: Enumerating objects: 121, done.\u001b[K\nremote: Counting objects: 100% (61/61), done.\u001b[K\nremote: Compressing objects: 100% (54/54), done.\u001b[K\nremote: Total 121 (delta 20), reused 0 (delta 0), pack-reused 60 (from 2)\u001b[K\nReceiving objects: 100% (121/121), 81.30 MiB | 26.62 MiB/s, done.\nResolving deltas: 100% (24/24), done.\nUpdating files: 100% (36/36), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport sys\nsys.path.insert(1, '/kaggle/working/chinese_word_segmentation/')\nos.chdir('/kaggle/working/chinese_word_segmentation/')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:46:22.652752Z","iopub.execute_input":"2024-12-24T22:46:22.652941Z","iopub.status.idle":"2024-12-24T22:46:22.656903Z","shell.execute_reply.started":"2024-12-24T22:46:22.652922Z","shell.execute_reply":"2024-12-24T22:46:22.656057Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import codecs\nimport argparse\nimport pickle\nimport warnings\nimport collections\nfrom utils import get_processing_word, read_pretrained_embeddings, is_dataset_tag, make_sure_path_exists, to_id_list\nfrom convert_corpus import convert_corpus\nfrom seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments,BertConfig\nimport numpy as np\nfrom tqdm import tqdm\nfrom torchcrf import CRF\nfrom copy import deepcopy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:46:22.657749Z","iopub.execute_input":"2024-12-24T22:46:22.658056Z","iopub.status.idle":"2024-12-24T22:46:38.480828Z","shell.execute_reply.started":"2024-12-24T22:46:22.658034Z","shell.execute_reply":"2024-12-24T22:46:38.480204Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"convert_corpus()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:46:38.485554Z","iopub.execute_input":"2024-12-24T22:46:38.485745Z","iopub.status.idle":"2024-12-24T22:49:27.749889Z","shell.execute_reply.started":"2024-12-24T22:46:38.485727Z","shell.execute_reply":"2024-12-24T22:49:27.749195Z"}},"outputs":[{"name":"stdout","text":"Converting sighan2005 Simplified Chinese corpus\nConverting sighan bakeoff 2005 corpus: pku\nConverting sighan bakeoff 2005 corpus: msr\nConverting sighan bakeoff 2005 corpus: as\nConverting sighan bakeoff 2005 corpus: cityu\nCombining sighan2005 corpus to one joint Simplified Chinese corpus\nConverting extra 6 corpora\nConverting corpus sxu\nConverting corpus ctb\nConverting corpus zx\nConverting corpus cnc\nConverting corpus udc\nConverting corpus wtb\nCombining those 10 corpora to one joint corpus\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"Instance = collections.namedtuple(\"Instance\", [\"sentence\", \"tags\"])\n\nUNK_TAG = \"<UNK>\"\nNONE_TAG = \"<NONE>\"\nSTART_TAG = \"<START>\"\nEND_TAG = \"<STOP>\"\nPADDING_CHAR = \"<*>\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:49:27.751208Z","iopub.execute_input":"2024-12-24T22:49:27.751446Z","iopub.status.idle":"2024-12-24T22:49:27.755556Z","shell.execute_reply.started":"2024-12-24T22:49:27.751426Z","shell.execute_reply":"2024-12-24T22:49:27.754633Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def read_file(filename, w2i, t2i, c2i, max_iter=sys.maxsize, processing_word=get_processing_word(lowercase=False)):\n    \"\"\"\n    Read in a dataset and turn it into a list of instances.\n    Modifies the w2i, t2is and c2i dicts, adding new words/attributes/tags/chars \n    as it s\n    ees them.\n    \"\"\"\n    instances = []\n    vocab_counter = collections.Counter()\n    niter = 0\n    with codecs.open(filename, \"r\", \"utf-8\") as f:\n        words, tags = [], []\n        for line in f:\n            line = line.strip()\n            if len(line) == 0 or line.startswith(\"-DOCSTART-\"):\n                if len(words) != 0:\n                    niter += 1\n                    if max_iter is not None and niter > max_iter:\n                        break\n                    instances.append(Instance(words, tags))\n                    words, tags = [], []\n            else:\n                word, tag = line.split()\n                word = processing_word(word)\n                vocab_counter[word] += 1\n                if word not in w2i:\n                    w2i[word] = len(w2i)\n                if tag not in t2i:\n                    t2i[tag] = len(t2i)\n                if is_dataset_tag(word):\n                    if word not in c2i:\n                        c2i[word] = len(c2i)\n                else:\n                    for c in word:\n                        if c not in c2i:\n                            c2i[c] = len(c2i)\n                words.append(w2i[word])\n                tags.append(t2i[tag])\n    return instances, vocab_counter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:49:27.756184Z","iopub.execute_input":"2024-12-24T22:49:27.756374Z","iopub.status.idle":"2024-12-24T22:49:27.771187Z","shell.execute_reply.started":"2024-12-24T22:49:27.756357Z","shell.execute_reply":"2024-12-24T22:49:27.770317Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"options = {'training_data':'./data/ctb/bmes/train-all.txt',\n          'dev_data':'./data/ctb/bmes/dev.txt',\n          'test_data':'./data/ctb/bmes/test.txt',\n          'output':'dataset/ctb/dataset.pkl'}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:49:27.772051Z","iopub.execute_input":"2024-12-24T22:49:27.772337Z","iopub.status.idle":"2024-12-24T22:49:27.786784Z","shell.execute_reply.started":"2024-12-24T22:49:27.772305Z","shell.execute_reply":"2024-12-24T22:49:27.786025Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"w2i = {}  # mapping from word to index\nt2i = {}  # mapping from tag to index\nc2i = {}\n\nprint('Making training dataset')\ntraining_instances, training_vocab = read_file(options['training_data'], w2i, t2i, c2i)\nprint('Making dev dataset')\ndev_instances, dev_vocab = read_file(options['dev_data'], w2i, t2i, c2i)\nprint('Making test dataset')\ntest_instances, test_vocab = read_file(options['test_data'], w2i, t2i, c2i)\n\n# Add special tokens / tags / chars to dicts\nw2i[UNK_TAG] = len(w2i)\nt2i[START_TAG] = len(t2i)\nt2i[END_TAG] = len(t2i)\nc2i[UNK_TAG] = len(c2i)\n\n\ni2w = to_id_list(w2i)  # Inverse mapping\ni2t = to_id_list(t2i)\ni2c = to_id_list(c2i)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:49:27.787575Z","iopub.execute_input":"2024-12-24T22:49:27.787793Z","iopub.status.idle":"2024-12-24T22:49:31.741728Z","shell.execute_reply.started":"2024-12-24T22:49:27.787774Z","shell.execute_reply":"2024-12-24T22:49:31.740631Z"}},"outputs":[{"name":"stdout","text":"Making training dataset\nMaking dev dataset\nMaking test dataset\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"MAX_LENGTH=128\nnum_labels = len(i2t)\n\n# Create a custom Dataset\nclass WordSegmentationDataset(Dataset):\n    def __init__(self, data, max_length=MAX_LENGTH, padding_tag = -100):\n        self.data = data\n        self.max_length = max_length\n        self.padding_tag = padding_tag\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        input_ids = self.data[idx].sentence\n        labels = self.data[idx].tags\n        length = len(input_ids)\n        # Padding\n        padding_length = self.max_length - len(input_ids)\n        if padding_length > 0:\n            input_ids = input_ids + ([0] * padding_length)\n            labels = labels + ([self.padding_tag] * padding_length)  # -100 will be ignored in loss calculation\n            attention_mask = [1] * (self.max_length -padding_length) + ([0] * padding_length)\n        else:\n            input_ids = input_ids[:self.max_length]\n            labels = labels[:self.max_length]\n            attention_mask = [1] * self.max_length\n        \n        return {\n            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n            'labels': torch.tensor(labels, dtype=torch.long),\n            'length': length\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:51:47.471865Z","iopub.execute_input":"2024-12-24T22:51:47.472188Z","iopub.status.idle":"2024-12-24T22:51:47.478355Z","shell.execute_reply.started":"2024-12-24T22:51:47.472166Z","shell.execute_reply":"2024-12-24T22:51:47.477586Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# BERT model","metadata":{}},{"cell_type":"code","source":"# Define compute_metrics function for evaluation\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n    \n    true_labels = []\n    true_predictions = []\n\n    for prediction, label in zip(predictions, labels):\n        temp_labels = []\n        temp_preds = []\n\n        for pred, lbl in zip(prediction, label):\n            if lbl != -100:\n                temp_labels.append(i2t[lbl])\n                temp_preds.append(i2t[pred])\n\n        true_labels.append(temp_labels)\n        true_predictions.append(temp_preds)\n    \n    return {\n        \"accuracy\": accuracy_score(true_labels, true_predictions),\n        \"precision\": precision_score(true_labels, true_predictions, average='macro'),\n        \"recall\": recall_score(true_labels, true_predictions, average='macro'),\n        \"f1\": f1_score(true_labels, true_predictions, average='macro'),\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:51:49.238624Z","iopub.execute_input":"2024-12-24T22:51:49.238921Z","iopub.status.idle":"2024-12-24T22:51:49.244659Z","shell.execute_reply.started":"2024-12-24T22:51:49.238896Z","shell.execute_reply":"2024-12-24T22:51:49.243747Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Bi-LSTM","metadata":{}},{"cell_type":"code","source":"class BiLSTMTagger(nn.Module):\n       def __init__(self, vocab_size, tagset_size, embedding_dim=256, hidden_dim=256, pad_token_id=0):\n           super(BiLSTMTagger, self).__init__()\n           self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_token_id)\n           self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=1, \n                               bidirectional=True, batch_first=True)\n           self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n       \n       def forward(self, input_ids, attention_mask, lengths):\n           embeds = self.embedding(input_ids)\n           packed_input = nn.utils.rnn.pack_padded_sequence(embeds, lengths, \n                                                            batch_first=True, enforce_sorted=False)\n           packed_output, _ = self.lstm(packed_input)\n           # Use total_length to ensure consistent sequence length\n           lstm_out, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True, \n                                                          total_length=input_ids.size(1))\n           tag_space = self.hidden2tag(lstm_out)\n           return tag_space","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:52:45.709703Z","iopub.execute_input":"2024-12-24T22:52:45.710035Z","iopub.status.idle":"2024-12-24T22:52:45.715927Z","shell.execute_reply.started":"2024-12-24T22:52:45.710002Z","shell.execute_reply":"2024-12-24T22:52:45.714809Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Initialize the model\nvocab_size = len(i2c) + 1  # +1 for padding token\ntagset_size = num_labels\npad_token_id = -100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:52:47.091943Z","iopub.execute_input":"2024-12-24T22:52:47.092302Z","iopub.status.idle":"2024-12-24T22:52:47.095870Z","shell.execute_reply.started":"2024-12-24T22:52:47.092273Z","shell.execute_reply":"2024-12-24T22:52:47.095065Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"bilstm_model = BiLSTMTagger(vocab_size, tagset_size, pad_token_id=pad_token_id)\nbilstm_model.load_state_dict(torch.load('./models/bilstm_model/bilstm_model.pth', weights_only=True))\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbilstm_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:52:48.657549Z","iopub.execute_input":"2024-12-24T22:52:48.657843Z","iopub.status.idle":"2024-12-24T22:52:48.759791Z","shell.execute_reply.started":"2024-12-24T22:52:48.657822Z","shell.execute_reply":"2024-12-24T22:52:48.759048Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"BiLSTMTagger(\n  (embedding): Embedding(4317, 256, padding_idx=4217)\n  (lstm): LSTM(256, 128, batch_first=True, bidirectional=True)\n  (hidden2tag): Linear(in_features=256, out_features=6, bias=True)\n)"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"# BERT-BiLSTM-CRF","metadata":{}},{"cell_type":"code","source":"from transformers import BertModel, BertConfig\nclass BertBiLSTMCRF(nn.Module):\n    def __init__(self, num_labels, vocab_size=30522,hidden_size=256,num_hidden_layers=4,\n                 num_attention_heads=8,intermediate_size=512,max_position_embeddings=MAX_LENGTH,\n                 hidden_dim_lstm=256, num_lstm_layers=1, pad_token=0):\n        super().__init__()\n        config = BertConfig(\n            vocab_size=vocab_size, hidden_size=hidden_size, num_hidden_layers=num_hidden_layers,\n            num_attention_heads=num_attention_heads, intermediate_size=intermediate_size,\n            pad_token_id=pad_token\n        )\n        self.bert = BertModel(config)\n        self.lstm = nn.LSTM(\n            input_size=hidden_size, hidden_size=hidden_dim_lstm // 2,\n            num_layers=num_lstm_layers, bidirectional=True, batch_first=True\n        )\n        self.fc = nn.Linear(hidden_dim_lstm, num_labels)\n        self.crf = CRF(num_labels, batch_first=True)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        lstm_out, _ = self.lstm(outputs.last_hidden_state)\n        emissions = self.fc(lstm_out)\n        if labels is not None:\n            loss = -self.crf(emissions, labels, mask=attention_mask.bool(), reduction='mean')\n            return loss\n        else:\n            return self.crf.decode(emissions, mask=attention_mask.bool())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:53:27.910715Z","iopub.execute_input":"2024-12-24T22:53:27.911096Z","iopub.status.idle":"2024-12-24T22:53:27.917605Z","shell.execute_reply.started":"2024-12-24T22:53:27.911062Z","shell.execute_reply":"2024-12-24T22:53:27.916899Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from transformers.models.bert.modeling_bert import BertEmbeddings\nfrom torch.nn.modules.sparse import Embedding\ntorch.serialization.add_safe_globals([Embedding])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T22:58:40.269077Z","iopub.execute_input":"2024-12-24T22:58:40.269375Z","iopub.status.idle":"2024-12-24T22:58:40.273438Z","shell.execute_reply.started":"2024-12-24T22:58:40.269354Z","shell.execute_reply":"2024-12-24T22:58:40.272564Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#bilstmbertcrf_model = BertBiLSTMCRF(num_labels=tagset_size, vocab_size=len(i2c)+1, pad_token=1)\n#bilstmbertcrf_model.load_state_dict(torch.load('./models/bilstmbertcrf_model/bilstmbertcrf_model.pth', weights_only=False))\nbilstmbertcrf_model =torch.load('./models/bilstmbertcrf_model/bilstmbertcrf_model.pth', weights_only=False)\nbilstmbertcrf_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T23:00:10.050436Z","iopub.execute_input":"2024-12-24T23:00:10.050844Z","iopub.status.idle":"2024-12-24T23:00:10.085862Z","shell.execute_reply.started":"2024-12-24T23:00:10.050810Z","shell.execute_reply":"2024-12-24T23:00:10.085030Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"BertBiLSTMCRF(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(4317, 256, padding_idx=0)\n      (position_embeddings): Embedding(512, 256)\n      (token_type_embeddings): Embedding(2, 256)\n      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-3): 4 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=256, out_features=256, bias=True)\n              (key): Linear(in_features=256, out_features=256, bias=True)\n              (value): Linear(in_features=256, out_features=256, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=256, out_features=256, bias=True)\n              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=256, out_features=512, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=512, out_features=256, bias=True)\n            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=256, out_features=256, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (lstm): LSTM(256, 128, batch_first=True, bidirectional=True)\n  (fc): Linear(in_features=256, out_features=6, bias=True)\n  (crf): CRF(num_tags=6)\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"markdown","source":"# Evaluating on test data","metadata":{}},{"cell_type":"code","source":"bert_model = BertForTokenClassification.from_pretrained('./models/bert_model')\n\ntest_args = TrainingArguments(\n     report_to=\"none\",\n    output_dir='./results',\n    do_train = False,\n    do_predict = True,\n    per_device_eval_batch_size = 32,   \n    dataloader_drop_last = False    \n)\n\n# init trainer\ntrainer = Trainer(\n              model = bert_model, \n              args = test_args, \n              compute_metrics = compute_metrics)\n\ntest_dataset = WordSegmentationDataset(test_instances)\ntest_results = trainer.predict(test_dataset)\ntest_results.metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T23:00:36.884084Z","iopub.execute_input":"2024-12-24T23:00:36.884416Z","iopub.status.idle":"2024-12-24T23:00:40.107875Z","shell.execute_reply.started":"2024-12-24T23:00:36.884389Z","shell.execute_reply":"2024-12-24T23:00:40.107198Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: M seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{'test_loss': 0.22861121594905853,\n 'test_accuracy': 0.9237090427939691,\n 'test_precision': 0.9047110611595017,\n 'test_recall': 0.9136792720531205,\n 'test_f1': 0.9091730512207518,\n 'test_runtime': 3.1533,\n 'test_samples_per_second': 2194.543,\n 'test_steps_per_second': 34.567}"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"test_dataset = WordSegmentationDataset(test_instances)\nbatch_size = 16\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\nbilstm_model.eval()\ntrue_labels = []\ntrue_predictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        lengths = batch['length']\n\n        \n        outputs = bilstm_model(input_ids, attention_mask, lengths)\n        \n        # Get predictions\n        _, preds = torch.max(outputs, dim=2)\n        \n        preds = preds.cpu().numpy()\n        labels = labels.cpu().numpy()\n        \n        for pred, label, mask in zip(preds, labels, attention_mask.cpu().numpy()):\n            temp_labels = []\n            temp_preds = []\n            \n            for i in range(len(pred)):\n                if mask[i]:\n                    temp_labels.append(i2t[label[i]])\n                    temp_preds.append(i2t[pred[i]])\n            true_labels.append(temp_labels)\n            true_predictions.append(temp_preds)\nacc = accuracy_score(true_labels, true_predictions)\nprec = precision_score(true_labels, true_predictions, average='macro')\nrec = recall_score(true_labels, true_predictions, average='macro')\nf1 = f1_score(true_labels, true_predictions, average='macro')\nprint(f\"Validation Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T23:02:00.294436Z","iopub.execute_input":"2024-12-24T23:02:00.294742Z","iopub.status.idle":"2024-12-24T23:02:02.892816Z","shell.execute_reply.started":"2024-12-24T23:02:00.294716Z","shell.execute_reply":"2024-12-24T23:02:02.891780Z"}},"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.9452, Precision: 0.9334, Recall: 0.9374, F1-score: 0.9354\n\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"test_dataset = WordSegmentationDataset(test_instances, padding_tag=1)\nbatch_size = 16\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\nbilstmbertcrf_model.eval()\ntrue_labels = []\ntrue_predictions = []\nfor batch in tqdm(test_loader):\n    with torch.no_grad():\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels']\n        \n        preds = bilstmbertcrf_model(input_ids, attention_mask)\n        \n        \n        for pred, label, mask in zip(preds, labels, attention_mask.cpu().numpy()):\n            temp_labels = []\n            temp_preds = []\n            \n            for i in range(len(pred)):\n                if mask[i]:\n                    temp_labels.append(i2t[label[i]])\n                    temp_preds.append(i2t[pred[i]])\n            true_labels.append(temp_labels)\n            true_predictions.append(temp_preds)\nacc = accuracy_score(true_labels, true_predictions)\nprec = precision_score(true_labels, true_predictions, average='macro')\nrec = recall_score(true_labels, true_predictions, average='macro')\nf1 = f1_score(true_labels, true_predictions, average='macro')\nprint(f\"Validation Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1-score: {f1:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T23:02:23.618407Z","iopub.execute_input":"2024-12-24T23:02:23.618699Z","iopub.status.idle":"2024-12-24T23:02:33.396197Z","shell.execute_reply.started":"2024-12-24T23:02:23.618678Z","shell.execute_reply":"2024-12-24T23:02:33.395227Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 433/433 [00:08<00:00, 49.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.9569, Precision: 0.9498, Recall: 0.9506, F1-score: 0.9502\n\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"# DEMO","metadata":{}},{"cell_type":"code","source":"sentence1 = '我喜欢编写自然语言处理机器学习任务'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T23:20:41.177646Z","iopub.execute_input":"2024-12-24T23:20:41.177982Z","iopub.status.idle":"2024-12-24T23:20:41.181768Z","shell.execute_reply.started":"2024-12-24T23:20:41.177929Z","shell.execute_reply":"2024-12-24T23:20:41.180981Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"def transform(sentence):\n    input_ids = [c2i[el] for el in sentence]\n    length = len(input_ids)\n    padding_length = MAX_LENGTH - len(input_ids)\n    input_ids = input_ids + ([0] * padding_length)\n    attention_mask = [1] * (MAX_LENGTH -padding_length) + ([0] * padding_length)\n    preds = bilstmbertcrf_model(torch.tensor(input_ids, dtype=torch.long).unsqueeze(0).to(device), torch.tensor(attention_mask, dtype=torch.long).unsqueeze(0).to(device))\n    ans = \"\"\n    for i in range(len(preds[0])):\n        ans+= sentence[i]\n        if preds[0][i]==1 or preds[0][i]==2:\n            ans += \" \"\n    return ans","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T23:20:42.204375Z","iopub.execute_input":"2024-12-24T23:20:42.204627Z","iopub.status.idle":"2024-12-24T23:20:42.210234Z","shell.execute_reply.started":"2024-12-24T23:20:42.204605Z","shell.execute_reply":"2024-12-24T23:20:42.209542Z"}},"outputs":[],"execution_count":102},{"cell_type":"code","source":"transform(sentence1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T23:20:43.210880Z","iopub.execute_input":"2024-12-24T23:20:43.211222Z","iopub.status.idle":"2024-12-24T23:20:43.236120Z","shell.execute_reply.started":"2024-12-24T23:20:43.211194Z","shell.execute_reply":"2024-12-24T23:20:43.235459Z"}},"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"'我 喜欢 编写 自然 语言 处理 机器 学习 任务 '"},"metadata":{}}],"execution_count":103}]}